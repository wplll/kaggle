{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## summary\n\n* 2.5d segmentation\n    *  segmentation_models_pytorch \n    *  Unet\n* use only 6 slices in the middle\n* slide inference","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\nimport pickle\nfrom torch.utils.data import DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nimport sys\nimport pandas as pd\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport cv2\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport argparse\nimport importlib\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD, AdamW\n\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:14:32.548986Z","iopub.execute_input":"2023-05-25T11:14:32.549626Z","iopub.status.idle":"2023-05-25T11:14:37.311188Z","shell.execute_reply.started":"2023-05-25T11:14:32.549593Z","shell.execute_reply":"2023-05-25T11:14:37.308851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n# sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n# sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n# sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:14:37.313397Z","iopub.execute_input":"2023-05-25T11:14:37.314740Z","iopub.status.idle":"2023-05-25T11:14:37.325072Z","shell.execute_reply.started":"2023-05-25T11:14:37.314707Z","shell.execute_reply":"2023-05-25T11:14:37.322709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:14:37.326632Z","iopub.execute_input":"2023-05-25T11:14:37.327034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.idle":"2023-05-25T11:14:58.045343Z","shell.execute_reply.started":"2023-05-25T11:14:55.215322Z","shell.execute_reply":"2023-05-25T11:14:58.044161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install warmup_scheduler","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:14:58.047006Z","iopub.execute_input":"2023-05-25T11:14:58.047451Z","iopub.status.idle":"2023-05-25T11:15:11.686609Z","shell.execute_reply.started":"2023-05-25T11:14:58.047402Z","shell.execute_reply":"2023-05-25T11:15:11.685056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:11.689528Z","iopub.execute_input":"2023-05-25T11:15:11.690229Z","iopub.status.idle":"2023-05-25T11:15:12.699677Z","shell.execute_reply.started":"2023-05-25T11:15:11.690170Z","shell.execute_reply":"2023-05-25T11:15:12.698605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"import os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass CFG:\n    # ============== comp exp name =============\n    comp_name = 'vesuvius'\n\n    # comp_dir_path = './'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'vesuvius-challenge-ink-detection'\n    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n    \n    exp_name = 'vesuvius_2d_slide_exp002'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n    backbone = 'resnet3d'\n    # backbone = 'se_resnext50_32x4d'\n    crop_depth = 5\n    in_chans = 11 # 65\n    # ============== training cfg =============\n    size = 224\n    tile_size = 224\n    stride = tile_size // 2\n\n    train_batch_size = 24 # 32\n    valid_batch_size = train_batch_size * 2\n    use_amp = True\n\n    scheduler = 'GradualWarmupSchedulerV2'\n    # scheduler = 'CosineAnnealingLR'\n    epochs = 30 # 30\n\n    # adamW warmupあり\n    warmup_factor = 10\n    # lr = 1e-4 / warmup_factor\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n    valid_id = 1\n\n    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n    # metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 4\n\n    seed = 42\n\n    # ============== set dataset path =============\n    print('set dataset path')\n\n    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n\n    submission_dir = outputs_path + 'submissions/'\n    submission_path = submission_dir + f'submission_{exp_name}.csv'\n\n    model_dir = outputs_path + \\\n        f'{comp_name}-models/'\n\n    figures_dir = outputs_path + 'figures/'\n\n    log_dir = outputs_path + 'logs/'\n    log_path = log_dir + f'{exp_name}.txt'\n\n    # ============== augmentation =============\n    train_aug_list = [\n        # A.RandomResizedCrop(\n        #     size, size, scale=(0.85, 1.0)),\n        A.Resize(size, size),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n                A.GaussNoise(var_limit=[10, 50]),\n                A.GaussianBlur(),\n                A.MotionBlur(),\n                ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n                        mask_fill_value=0, p=0.5),\n        # A.Cutout(max_h_size=int(size * 0.6),\n        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.701253Z","iopub.execute_input":"2023-05-25T11:15:12.701658Z","iopub.status.idle":"2023-05-25T11:15:12.721537Z","shell.execute_reply.started":"2023-05-25T11:15:12.701617Z","shell.execute_reply":"2023-05-25T11:15:12.720361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## helper","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.723094Z","iopub.execute_input":"2023-05-25T11:15:12.724015Z","iopub.status.idle":"2023-05-25T11:15:12.738671Z","shell.execute_reply.started":"2023-05-25T11:15:12.723970Z","shell.execute_reply":"2023-05-25T11:15:12.737485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_logger(log_file):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\ndef set_seed(seed=None, cudnn_deterministic=True):\n    if seed is None:\n        seed = 42\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = cudnn_deterministic\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.740624Z","iopub.execute_input":"2023-05-25T11:15:12.741171Z","iopub.status.idle":"2023-05-25T11:15:12.752680Z","shell.execute_reply.started":"2023-05-25T11:15:12.741116Z","shell.execute_reply":"2023-05-25T11:15:12.751662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dirs(cfg):\n    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir]:\n        os.makedirs(dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.758255Z","iopub.execute_input":"2023-05-25T11:15:12.758650Z","iopub.status.idle":"2023-05-25T11:15:12.768134Z","shell.execute_reply.started":"2023-05-25T11:15:12.758620Z","shell.execute_reply":"2023-05-25T11:15:12.767066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cfg_init(cfg, mode='train'):\n    set_seed(cfg.seed)\n    # set_env_name()\n    # set_dataset_path(cfg)\n\n    if mode == 'train':\n        make_dirs(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.769821Z","iopub.execute_input":"2023-05-25T11:15:12.770188Z","iopub.status.idle":"2023-05-25T11:15:12.779387Z","shell.execute_reply.started":"2023-05-25T11:15:12.770151Z","shell.execute_reply":"2023-05-25T11:15:12.778262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg_init(CFG)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nLogger = init_logger(log_file=CFG.log_path)\n\nLogger.info('\\n\\n-------- exp_info -----------------')\n# Logger.info(datetime.datetime.now().strftime('%Y年%m月%d日 %H:%M:%S'))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.782159Z","iopub.execute_input":"2023-05-25T11:15:12.782953Z","iopub.status.idle":"2023-05-25T11:15:12.894433Z","shell.execute_reply.started":"2023-05-25T11:15:12.782910Z","shell.execute_reply":"2023-05-25T11:15:12.893332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## image, mask","metadata":{}},{"cell_type":"code","source":"def read_image_mask(fragment_id):\n\n    images = []\n\n    # idxs = range(65)\n    mid = 65 // 2\n    start = mid - 5\n    end = start + CFG.in_chans\n    idxs = range(start, end)\n\n    for i in tqdm(idxs):\n        \n        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n\n        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n\n        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n\n        images.append(image)\n    images = np.stack(images, axis=2)\n\n    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n\n    mask = mask.astype('float32')\n    mask /= 255.0\n    \n    return images, mask","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.896080Z","iopub.execute_input":"2023-05-25T11:15:12.896468Z","iopub.status.idle":"2023-05-25T11:15:12.908637Z","shell.execute_reply.started":"2023-05-25T11:15:12.896435Z","shell.execute_reply":"2023-05-25T11:15:12.907227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_valid_dataset():\n    train_images = []\n    train_masks = []\n\n    valid_images = []\n    valid_masks = []\n    valid_xyxys = []\n\n    for fragment_id in range(1, 4):\n\n        image, mask = read_image_mask(fragment_id)\n\n        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n\n        for y1 in y1_list:\n            for x1 in x1_list:\n                y2 = y1 + CFG.tile_size\n                x2 = x1 + CFG.tile_size\n                # xyxys.append((x1, y1, x2, y2))\n        \n                if fragment_id == CFG.valid_id:\n                    valid_images.append(image[y1:y2, x1:x2])\n                    valid_masks.append(mask[y1:y2, x1:x2, None])\n\n                    valid_xyxys.append([x1, y1, x2, y2])\n                else:\n                    train_images.append(image[y1:y2, x1:x2])\n                    train_masks.append(mask[y1:y2, x1:x2, None])\n\n    return train_images, train_masks, valid_images, valid_masks, valid_xyxys","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.910894Z","iopub.execute_input":"2023-05-25T11:15:12.911974Z","iopub.status.idle":"2023-05-25T11:15:12.923782Z","shell.execute_reply.started":"2023-05-25T11:15:12.911935Z","shell.execute_reply":"2023-05-25T11:15:12.922716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:15:12.924885Z","iopub.execute_input":"2023-05-25T11:15:12.925174Z","iopub.status.idle":"2023-05-25T11:16:32.827708Z","shell.execute_reply.started":"2023-05-25T11:15:12.925146Z","shell.execute_reply":"2023-05-25T11:16:32.826544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_xyxys = np.stack(valid_xyxys)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:32.829223Z","iopub.execute_input":"2023-05-25T11:16:32.829656Z","iopub.status.idle":"2023-05-25T11:16:32.849658Z","shell.execute_reply.started":"2023-05-25T11:16:32.829608Z","shell.execute_reply":"2023-05-25T11:16:32.848318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:32.851673Z","iopub.execute_input":"2023-05-25T11:16:32.852429Z","iopub.status.idle":"2023-05-25T11:16:32.863791Z","shell.execute_reply.started":"2023-05-25T11:16:32.852383Z","shell.execute_reply":"2023-05-25T11:16:32.862676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n\n    # print(aug)\n    return aug\n\nclass CustomDataset(Dataset):\n    def __init__(self, images, cfg, labels=None, transform=None):\n        self.images = images\n        self.cfg = cfg\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        # return len(self.df)\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            data = self.transform(image=image, mask=label)\n            image = data['image']\n            label = data['mask']\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:32.865258Z","iopub.execute_input":"2023-05-25T11:16:32.865705Z","iopub.status.idle":"2023-05-25T11:16:32.880165Z","shell.execute_reply.started":"2023-05-25T11:16:32.865667Z","shell.execute_reply":"2023-05-25T11:16:32.879177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataset = CustomDataset(\n    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\nvalid_dataset = CustomDataset(\n    valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=CFG.train_batch_size,\n                          shuffle=True,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n                          )\nvalid_loader = DataLoader(valid_dataset,\n                          batch_size=CFG.valid_batch_size,\n                          shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:32.881778Z","iopub.execute_input":"2023-05-25T11:16:32.882221Z","iopub.status.idle":"2023-05-25T11:16:32.896590Z","shell.execute_reply.started":"2023-05-25T11:16:32.882178Z","shell.execute_reply":"2023-05-25T11:16:32.895363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:32.898151Z","iopub.execute_input":"2023-05-25T11:16:32.898659Z","iopub.status.idle":"2023-05-25T11:16:32.974351Z","shell.execute_reply.started":"2023-05-25T11:16:32.898620Z","shell.execute_reply":"2023-05-25T11:16:32.973339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplot_dataset = CustomDataset(\n    train_images, CFG, labels=train_masks)\n\ntransform = CFG.train_aug_list\ntransform = A.Compose(\n    [t for t in transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n\n\nplot_count = 0\nfor i in range(1000):\n\n    image, mask = plot_dataset[i]\n    data = transform(image=image, mask=mask)\n    aug_image = data['image']\n    aug_mask = data['mask']\n\n    if mask.sum() == 0:\n        continue\n\n    fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n    axes[0].imshow(image[..., 0], cmap=\"gray\")\n    axes[1].imshow(mask, cmap=\"gray\")\n    axes[2].imshow(aug_image[..., 0], cmap=\"gray\")\n    axes[3].imshow(aug_mask, cmap=\"gray\")\n    \n    plt.savefig(CFG.figures_dir + f'aug_fold_{CFG.valid_id}_{plot_count}.png')\n\n    plot_count += 1\n    if plot_count == 5:\n        break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-25T11:16:32.976162Z","iopub.execute_input":"2023-05-25T11:16:32.976958Z","iopub.status.idle":"2023-05-25T11:16:40.275709Z","shell.execute_reply.started":"2023-05-25T11:16:32.976918Z","shell.execute_reply":"2023-05-25T11:16:40.274522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del plot_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.277218Z","iopub.execute_input":"2023-05-25T11:16:40.277682Z","iopub.status.idle":"2023-05-25T11:16:40.476242Z","shell.execute_reply.started":"2023-05-25T11:16:40.277639Z","shell.execute_reply":"2023-05-25T11:16:40.475090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"# class CustomModel(nn.Module):\n#     def __init__(self, cfg, weight=None):\n#         super().__init__()\n#         self.cfg = cfg\n\n#         self.encoder = smp.Unet(\n#             encoder_name=cfg.backbone, \n#             encoder_weights=weight,\n#             in_channels=cfg.in_chans,\n#             classes=cfg.target_size,\n#             activation=None,\n#         )\n\n#     def forward(self, image):\n#         output = self.encoder(image)\n#         # output = output.squeeze(-1)\n#         return output\n\n\n# def build_model(cfg, weight=\"imagenet\"):\n#     print('model_name', cfg.model_name)\n#     print('backbone', cfg.backbone)\n\n#     model = CustomModel(cfg, weight)\n\n#     return model","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.477783Z","iopub.execute_input":"2023-05-25T11:16:40.479104Z","iopub.status.idle":"2023-05-25T11:16:40.487105Z","shell.execute_reply.started":"2023-05-25T11:16:40.479067Z","shell.execute_reply":"2023-05-25T11:16:40.485772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/einops/einops-master')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.489032Z","iopub.execute_input":"2023-05-25T11:16:40.489467Z","iopub.status.idle":"2023-05-25T11:16:40.497655Z","shell.execute_reply.started":"2023-05-25T11:16:40.489425Z","shell.execute_reply":"2023-05-25T11:16:40.496567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from einops import rearrange, reduce, repeat\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.decoders.unet.decoder import DecoderBlock\nfrom timm.models.resnet import *\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.499335Z","iopub.execute_input":"2023-05-25T11:16:40.499892Z","iopub.status.idle":"2023-05-25T11:16:40.544267Z","shell.execute_reply.started":"2023-05-25T11:16:40.499854Z","shell.execute_reply":"2023-05-25T11:16:40.543338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## model ##\nclass SmpUnetDecoder(nn.Module):\n\tdef __init__(self,\n\t         in_channel,\n\t         skip_channel,\n\t         out_channel,\n\t    ):\n\t\tsuper().__init__()\n\t\tself.center = nn.Identity()\n\n\t\ti_channel = [in_channel,]+ out_channel[:-1]  #512, 256, 128, 64\n\t\ts_channel = skip_channel  #256, 128, 64, 64\n\t\to_channel = out_channel#256, 128, 64, 64\n\t\tblock = [\n\t\t\tDecoderBlock(i, s, o, use_batchnorm=True, attention_type=None)\n\t\t\tfor i, s, o in zip(i_channel, s_channel, o_channel)\n\t\t]\n\t\tself.block = nn.ModuleList(block)\n\n\tdef forward(self, feature, skip):\n\t\td = self.center(feature)\n\t\tdecode = []\n\t\tfor i, block in enumerate(self.block):\n\t\t\ts = skip[i]\n\t\t\td = block(d, s)\n\t\t\tdecode.append(d)\n\n\t\tlast  = d\n\t\treturn last, decode\n\nclass Net(nn.Module):\n\tdef __init__(self,):\n\t\tsuper().__init__()\n\t\tself.output_type = ['inference', 'loss']\n\n\t\tconv_dim = 64\n\t\tencoder1_dim  = [conv_dim, 64, 128, 256, 512, ]\n\t\tdecoder1_dim  = [256, 128, 64, 64,]\n\n\t\tself.encoder1 = resnet34d(pretrained=True, in_chans=CFG.crop_depth)\n\n\t\tself.decoder1 = SmpUnetDecoder(\n\t\t\tin_channel   = encoder1_dim[-1], #512\n\t\t\tskip_channel = encoder1_dim[:-1][::-1], #256, 128, 64, 64\n\t\t\tout_channel  = decoder1_dim,   #256, 128, 64, 64\n\t\t)\n\t\t# -- pool attention weight\n\t\tself.weight1 = nn.ModuleList([\n\t\t\tnn.Sequential(\n\t\t\t\tnn.Conv2d(dim, dim, kernel_size=3, padding=1),\n\t\t\t\tnn.ReLU(inplace=True),\n\t\t\t) for dim in encoder1_dim\n\t\t])\n\t\tself.logit1 = nn.Conv2d(decoder1_dim[-1],1,kernel_size=1)\n\n\t\t#--------------------------------\n\t\t#\n\t\tencoder2_dim  = [64, 128, 256, 512]#\n\t\tdecoder2_dim  = [128, 64, 32, ]\n\t\tself.encoder2 = resnet10t(pretrained=True, in_chans=decoder1_dim[-1])\n\n\t\tself.decoder2 = SmpUnetDecoder(\n\t\t\tin_channel   = encoder2_dim[-1],\n\t\t\tskip_channel = encoder2_dim[:-1][::-1],\n\t\t\tout_channel  = decoder2_dim,\n\t\t)\n\t\tself.logit2 = nn.Conv2d(decoder2_dim[-1],1,kernel_size=1)\n\n\tdef forward(self, batch):\n# \t\tv = batch['volume']\n\t\tv = batch\n\t\tB,C,H,W = v.shape\n\t\tvv = [\n\t\t\tv[:,i:i+CFG.crop_depth] for i in [0,2,4,]\n\t\t]\n\t\tK = len(vv)\n\t\tx = torch.cat(vv,0)\n\t\t#x = v\n\n\t\t#----------------------\n\t\tencoder = []\n\t\te = self.encoder1\n\t\tx = e.conv1(x)\n\t\tx = e.bn1(x)\n\t\tx = e.act1(x);\n\t\tencoder.append(x)\n\t\tx = F.avg_pool2d(x, kernel_size=2, stride=2)\n\t\tx = e.layer1(x);\n\t\tencoder.append(x)\n\t\tx = e.layer2(x);\n\t\tencoder.append(x)\n\t\tx = e.layer3(x);\n\t\tencoder.append(x)\n\t\tx = e.layer4(x);\n\t\tencoder.append(x)\n\t\t# print('encoder', [f.shape for f in encoder])\n\n#         类似于注意力\n\t\tfor i in range(len(encoder)):\n\t\t\te = encoder[i]\n\t\t\tf = self.weight1[i](e)\n\t\t\t_, c, h, w = e.shape\n\t\t\tf = rearrange(f, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n\t\t\te = rearrange(e, '(K B) c h w -> B K c h w', K=K, B=B, h=h, w=w)  #\n\t\t\tw = F.softmax(f, 1)\n\t\t\te = (w * e).sum(1)\n\t\t\tencoder[i] = e\n\n\t\tfeature = encoder[-1]\n\t\tskip = encoder[:-1][::-1]\n\t\tlast, decoder = self.decoder1(feature, skip)\n\t\tlogit1 = self.logit1(last)\n\n\t\t#----------------------\n\t\tx = last #.detach()\n\t\t#x = F.avg_pool2d(x,kernel_size=2,stride=2)\n\t\tencoder = []\n\t\te = self.encoder2\n\t\tx = e.layer1(x); encoder.append(x)\n\t\tx = e.layer2(x); encoder.append(x)\n\t\tx = e.layer3(x); encoder.append(x)\n\t\tx = e.layer4(x); encoder.append(x)\n\n\t\tfeature = encoder[-1]\n\t\tskip = encoder[:-1][::-1]\n\t\tlast, decoder = self.decoder2(feature, skip)\n\t\tlogit2 = self.logit2(last)\n\t\tlogit2 = F.interpolate(logit2, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n\n\t\toutput = {\n\t\t\t'ink' : torch.sigmoid(logit2),\n\t\t}\n\t\treturn output\n\ndef run_check_net():\n\n\theight,width =  CFG.tile_size, CFG.tile_size\n\tdepth = CFG.in_chans\n\tbatch_size = 3\n\n\tbatch = {\n\t\t'volume' : torch.from_numpy( np.random.choice(256, (batch_size, depth, height, width))).cuda().float(),\n\t}\n\tnet = Net().cuda()\n\n\twith torch.no_grad():\n\t\twith torch.cuda.amp.autocast(enabled=True):\n\t\t\toutput = net(batch)\n\n\t#---\n\tprint('batch')\n\tfor k, v in batch.items():\n\t\tprint(f'{k:>32} : {v.shape} ')\n\n\tprint('output')\n\tfor k, v in output.items():\n\t\tprint(f'{k:>32} : {v.shape} ')\n\n\n# run_check_net()\nprint('net ok !!!')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.547620Z","iopub.execute_input":"2023-05-25T11:16:40.547950Z","iopub.status.idle":"2023-05-25T11:16:40.583228Z","shell.execute_reply.started":"2023-05-25T11:16:40.547920Z","shell.execute_reply":"2023-05-25T11:16:40.581898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## scheduler","metadata":{}},{"cell_type":"code","source":"\nimport torch.nn as nn\nimport torch\nimport math\nimport time\nimport numpy as np\nimport torch\n\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom warmup_scheduler import GradualWarmupScheduler\n\n\nclass GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    \"\"\"\n    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n    \"\"\"\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(\n            optimizer, multiplier, total_epoch, after_scheduler)\n\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [\n                        base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\ndef get_scheduler(cfg, optimizer):\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, cfg.epochs, eta_min=1e-7)\n    scheduler = GradualWarmupSchedulerV2(\n        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n\n    return scheduler\n\ndef scheduler_step(scheduler, avg_val_loss, epoch):\n    scheduler.step(epoch)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.584699Z","iopub.execute_input":"2023-05-25T11:16:40.585125Z","iopub.status.idle":"2023-05-25T11:16:40.602475Z","shell.execute_reply.started":"2023-05-25T11:16:40.585087Z","shell.execute_reply":"2023-05-25T11:16:40.601457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net()\nmodel = nn.DataParallel(model, device_ids=[0, 1])\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=CFG.lr)\nscheduler = get_scheduler(CFG, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:40.609403Z","iopub.execute_input":"2023-05-25T11:16:40.609701Z","iopub.status.idle":"2023-05-25T11:16:46.541616Z","shell.execute_reply.started":"2023-05-25T11:16:40.609672Z","shell.execute_reply":"2023-05-25T11:16:46.540485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## loss","metadata":{}},{"cell_type":"code","source":"\nDiceLoss = smp.losses.DiceLoss(mode='binary')\nBCELoss = smp.losses.SoftBCEWithLogitsLoss()\n\nalpha = 0.5\nbeta = 1 - alpha\nTverskyLoss = smp.losses.TverskyLoss(\n    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n\ndef criterion(y_pred, y_true):\n    return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n#     return BCELoss(y_pred, y_true)\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:46.543233Z","iopub.execute_input":"2023-05-25T11:16:46.543794Z","iopub.status.idle":"2023-05-25T11:16:46.551850Z","shell.execute_reply.started":"2023-05-25T11:16:46.543741Z","shell.execute_reply":"2023-05-25T11:16:46.550688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train, val","metadata":{}},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, device):\n    model.train()\n\n    scaler = GradScaler(enabled=CFG.use_amp)\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with autocast(CFG.use_amp):\n            y_preds = model(images)\n            loss = criterion(y_preds['ink'], labels)\n\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n\n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            model.parameters(), CFG.max_grad_norm)\n\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt):\n    mask_pred = np.zeros(valid_mask_gt.shape)\n    mask_count = np.zeros(valid_mask_gt.shape)\n\n    model.eval()\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n            loss = criterion(y_preds['ink'], labels)\n        losses.update(loss.item(), batch_size)\n\n        # make whole mask\n        y_preds = torch.sigmoid(y_preds['ink']).to('cpu').numpy()\n        start_idx = step*CFG.valid_batch_size\n        end_idx = start_idx + batch_size\n#         print(mask_pred.shape,'mask_pred')\n#         print(y_preds.shape, 'y_preds')\n        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n\n    print(f'mask_count_min: {mask_count.min()}')\n    mask_pred /= mask_count\n    return losses.avg, mask_pred","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:46.553824Z","iopub.execute_input":"2023-05-25T11:16:46.554755Z","iopub.status.idle":"2023-05-25T11:16:46.573790Z","shell.execute_reply.started":"2023-05-25T11:16:46.554715Z","shell.execute_reply":"2023-05-25T11:16:46.572700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\n\ndef fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n    \"\"\"\n    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n    \"\"\"\n    y_true_count = targets.sum()\n    ctp = preds[targets==1].sum()\n    cfp = preds[targets==0].sum()\n    beta_squared = beta * beta\n\n    c_precision = ctp / (ctp + cfp + smooth)\n    c_recall = ctp / (y_true_count + smooth)\n    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n\n    return dice\n\ndef calc_fbeta(mask, mask_pred):\n    mask = mask.astype(int).flatten()\n    mask_pred = mask_pred.flatten()\n\n    best_th = 0\n    best_dice = 0\n    for th in np.array(range(10, 50+1, 5)) / 100:\n        \n        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n        print(f'th: {th}, fbeta: {dice}')\n\n        if dice > best_dice:\n            best_dice = dice\n            best_th = th\n    \n    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n    return best_dice, best_th\n\n\ndef calc_cv(mask_gt, mask_pred):\n    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n\n    return best_dice, best_th","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:46.576653Z","iopub.execute_input":"2023-05-25T11:16:46.577849Z","iopub.status.idle":"2023-05-25T11:16:46.590618Z","shell.execute_reply.started":"2023-05-25T11:16:46.577805Z","shell.execute_reply":"2023-05-25T11:16:46.589538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## main","metadata":{}},{"cell_type":"code","source":"fragment_id = CFG.valid_id\n\nvalid_mask_gt = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\nvalid_mask_gt = valid_mask_gt / 255\npad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\npad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\nvalid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:46.592146Z","iopub.execute_input":"2023-05-25T11:16:46.592571Z","iopub.status.idle":"2023-05-25T11:16:47.801998Z","shell.execute_reply.started":"2023-05-25T11:16:46.592526Z","shell.execute_reply":"2023-05-25T11:16:47.800869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:47.803585Z","iopub.execute_input":"2023-05-25T11:16:47.804674Z","iopub.status.idle":"2023-05-25T11:16:47.810669Z","shell.execute_reply.started":"2023-05-25T11:16:47.804628Z","shell.execute_reply":"2023-05-25T11:16:47.809604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfold = CFG.valid_id\n\nif CFG.metric_direction == 'minimize':\n    best_score = np.inf\nelif CFG.metric_direction == 'maximize':\n    best_score = -1\n\nbest_loss = np.inf\n\nfor epoch in range(CFG.epochs):\n\n    start_time = time.time()\n\n    # train\n    avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n\n    # eval\n    avg_val_loss, mask_pred = valid_fn(\n        valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt)\n\n    scheduler_step(scheduler, avg_val_loss, epoch)\n\n    best_dice, best_th = calc_cv(valid_mask_gt, mask_pred)\n\n    # score = avg_val_loss\n    score = best_dice\n\n    elapsed = time.time() - start_time\n\n    Logger.info(\n        f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n    # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n    Logger.info(\n        f'Epoch {epoch+1} - avgScore: {score:.4f}')\n\n    if CFG.metric_direction == 'minimize':\n        update_best = score < best_score\n    elif CFG.metric_direction == 'maximize':\n        update_best = score > best_score\n\n    if update_best:\n        best_loss = avg_val_loss\n        best_score = score\n\n        Logger.info(\n            f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n        Logger.info(\n            f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n        \n        torch.save({'model': model.state_dict(),\n                    'preds': mask_pred},\n                    CFG.model_dir + f'{CFG.model_name}_fold{fold}_best.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:16:47.812191Z","iopub.execute_input":"2023-05-25T11:16:47.813400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_point = torch.load(\n    CFG.model_dir + f'{CFG.model_name}_fold{fold}_{CFG.inf_weight}.pth', map_location=torch.device('cpu'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_pred = check_point['preds']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_dice, best_th  = calc_fbeta(valid_mask_gt, mask_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15, 8))\naxes[0].imshow(valid_mask_gt)\naxes[1].imshow(mask_pred)\naxes[2].imshow((mask_pred>=best_th).astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(mask_pred.flatten(), bins=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}